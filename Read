import cv2

def generate_dataset():
    face_classifier = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

    def face_cropped(img):
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converting into grayscale to reduce compelxity of rgb image
        faces = face_classifier.detectMultiScale(gray, 1.3, 5)
        #sacling factor=1.3 you have to scale your gray scale image
        #Minimum neighbour=5 upto what much neighbour you are going to detect face
        if len(faces) == 0:
            return None
        
        for (x, y, w, h) in faces:
            cropped_face = img[y:y+h, x:x+w] #croppping only face parts cordinate x means height and w means width
            break  # Break after the first face is detected
        
        return cropped_face
    
    cap = cv2.VideoCapture(0)  # Use 0 if 1 doesn't work
    id = 1 #chane it if you want to collect dataset of another person
    img_id = 0
    
    while True:  #infite loop
        ret, frame = cap.read()
        if face_cropped(frame) is not None:
            img_id += 1
            face = cv2.resize(face_cropped(frame), (200, 200))  #resizing image with coord 200200
            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
            file_name_path = "data/user." + str(id) + "." + str(img_id) + ".jpg" #storing images into folder data
            cv2.imwrite(file_name_path, face)
            cv2.putText(face, str(img_id), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)   #green color 2 is thickness font scale is 1
                                            #50 50 is the origin point from where text is to be written
            cv2.imshow("Cropped face", face)
        
        if cv2.waitKey(1) == 13 or int(img_id) == 200:  # 13 is the ASCII code for Enter
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("Collecting samples is completed....")

generate_dataset()
#-----------
import os
import cv2
from PIL import Image #pip install pillow
import numpy as np    # pip install numpy
 
def train_classifier(data_dir):
    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]
     
    faces = []
    ids = []
     
    for image in path:
        img = Image.open(image).convert('L')
        imageNp = np.array(img, 'uint8')
        id = int(os.path.split(image)[1].split(".")[1])
         
        faces.append(imageNp)
        ids.append(id)
         
    ids = np.array(ids)
     
    # Train and save classifier
    clf = cv2.face.LBPHFaceRecognizer_create()
    clf.train(faces,ids)
    clf.write("classifier.xml")
train_classifier("data")
#----------------
            import cv2
import numpy as np

def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):
    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)
     
    for (x, y, w, h) in features:
        cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)
         
        id, pred = clf.predict(gray_img[y:y+h, x:x+w])
        confidence = int(100 * (1 - pred / 300))
         
        if confidence > 50:
            if id == 1:
                cv2.putText(img, "Rahul", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
            elif id == 2:
                cv2.putText(img, "Manish", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
        else:
            cv2.putText(img, "UNKNOWN", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 1, cv2.LINE_AA)
     
    return img

# Load classifier
faceCascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

# Load trained recognizer model
clf = cv2.face.LBPHFaceRecognizer_create()
clf.read("classifier.xml")

# Start video capture
video_capture = cv2.VideoCapture(0)  # Change to 0 if using the default webcam

if not video_capture.isOpened():
    print("Error: Could not open webcam.")
    exit()

while True:
    ret, img = video_capture.read()
    if not ret:
        print("Failed to grab frame")
        break
    
    img = draw_boundary(img, faceCascade, 1.3, 6, (255, 255, 255), "Face", clf)
    cv2.imshow("Face Detection", img)
    
    # Exit on 'Enter' key
    if cv2.waitKey(1) == 13:
        break

# Release resources
video_capture.release()
cv2.destroyAllWindows()
